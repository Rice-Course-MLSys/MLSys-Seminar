[{"id":0,"href":"/MLSys-Seminar/collapse/level-1/","title":"Level 1","parent":"Collapse","content":"Level 1\nLevel 1.1 Level 1.2 ","description":"Level 1\nLevel 1.1 Level 1.2 "},{"id":1,"href":"/MLSys-Seminar/collapse/level-2/","title":"Level 2","parent":"Collapse","content":"Level-2\n","description":"Level-2\n"},{"id":2,"href":"/MLSys-Seminar/staffers/yuke/","title":"Yuke","parent":"Staff","content":"","description":""},{"id":3,"href":"/MLSys-Seminar/toc-tree/level-1/","title":"Level 1","parent":"ToC-Tree","content":"Level 1\nLevel 1.1 Level 1.2 Level 1.3 Level 1.3.1 ","description":"Level 1\nLevel 1.1 Level 1.2 Level 1.3 Level 1.3.1 "},{"id":4,"href":"/MLSys-Seminar/toc-tree/level-2/","title":"Level 2","parent":"ToC-Tree","content":"Level-2\n","description":"Level-2\n"},{"id":5,"href":"/MLSys-Seminar/about/","title":"About","parent":"Machine Learning System Seminar","content":"This course is a research seminar focused on efficient machine learning systems. This is a crucial area as modern deep neural networks, especially Large Language Models (LLMs) and generative models, demand extraordinary levels of computation. This computational cost hinders their deployment and scaling, creating significant challenges for both resource-constrained edge devices and large-scale cloud infrastructure. This course delves into the cutting-edge techniques that enable powerful and efficient AI applications.\nWe will cover the full stack of AI systems, from low-level kernel optimizations to high-level algorithm and model designs. The course will survey and dissect recent influential research papers in the field.\nTopics include:\nKernel-Level Optimizations: I/O-aware and exact attention mechanisms (e.g., FlashAttention), sparse attention, and custom kernel generation with AI compilers (e.g., TVM, MLIR).\nEfficient LLMs: State-of-the-art techniques for efficient training (e.g., ZeRO, LoRA), inference (e.g., vLLM, speculative decoding), model compression (quantization, pruning), and long-context optimizations.\nEfficient Model Architectures: Design principles for efficient models, including Mixture-of-Experts (MoE) and State Space Models (Mamba).\nGenerative AI Systems: Optimization techniques for emerging modalities, including efficient video generation, super-resolution, and understanding.\nSecure and Private AI: Methods for ensuring model and data security, including watermarking and encryption in the context of large models.models\nThis course is run as a research seminar. The focus will be on critically reading, presenting, and discussing influential papers in efficient AI systems. Through weekly readings and student-led presentations, participants will gain a deep understanding of the key challenges, foundational techniques, and future directions in the field. Approximately every two weeks, we will also host a guest lecture from a leading researcher or engineer from academia or industry, providing direct insights into the state-of-the-art.\nLecture Videos: [Link to be provided]\nTime: Friday 3:00 PM–4:15 PM CST\nLocation: [TBA]\nOffice Hour: [TBA]\nDiscussion: [TBA]\nHomework Submission: [TBA]\nContact:\n[TBD]\nPrerequisites:\n[TBD]\n","description":"This course is a research seminar focused on efficient machine learning systems. This is a crucial area as modern deep neural networks, especially Large Language Models (LLMs) and generative models, demand extraordinary levels of computation. This computational cost hinders their deployment and scaling, creating significant challenges for both resource-constrained edge devices and large-scale cloud infrastructure. This course delves into the cutting-edge techniques that enable powerful and efficient AI applications.\nWe will cover the full stack of AI systems, from low-level kernel optimizations to high-level algorithm and model designs. The course will survey and dissect recent influential research papers in the field.\n"},{"id":6,"href":"/MLSys-Seminar/collapse/","title":"Collapse","parent":"Machine Learning System Seminar","content":"Demo collapsible menu entries.\n","description":"Demo collapsible menu entries.\n"},{"id":7,"href":"/MLSys-Seminar/collapse/level-1/level-1-1/","title":"Level 1.1","parent":"Level 1","content":"Level 1.1\n","description":"Level 1.1\n"},{"id":8,"href":"/MLSys-Seminar/toc-tree/level-1/level-1-1/","title":"Level 1.1","parent":"Level 1","content":"Level 1.1\n","description":"Level 1.1\n"},{"id":9,"href":"/MLSys-Seminar/collapse/level-1/level-1-2/","title":"Level 1.2","parent":"Level 1","content":"Level 1.2\n","description":"Level 1.2\n"},{"id":10,"href":"/MLSys-Seminar/toc-tree/level-1/level-1-2/","title":"Level 1.2","parent":"Level 1","content":"Level 1.2\n","description":"Level 1.2\n"},{"id":11,"href":"/MLSys-Seminar/toc-tree/level-1/level-1-3/","title":"Level 1.3","parent":"Level 1","content":"Level 1.3\nLevel 1.3.1 ","description":"Level 1.3\nLevel 1.3.1 "},{"id":12,"href":"/MLSys-Seminar/toc-tree/level-1/level-1-3/level-1-3-1/","title":"Level 1.3.1","parent":"Level 1.3","content":"Level 1.3.1\n","description":"Level 1.3.1\n"},{"id":13,"href":"/MLSys-Seminar/collapse/level-2/level-2-1/","title":"Level 2.1","parent":"Level 2","content":"Level 2.1\n","description":"Level 2.1\n"},{"id":14,"href":"/MLSys-Seminar/toc-tree/level-2/level-2-1/","title":"Level 2.1","parent":"Level 2","content":"Level 2.1\n","description":"Level 2.1\n"},{"id":15,"href":"/MLSys-Seminar/collapse/level-2/level-2-2/","title":"Level 2.2","parent":"Level 2","content":"Level 2.2\n","description":"Level 2.2\n"},{"id":16,"href":"/MLSys-Seminar/toc-tree/level-2/level-2-2/","title":"Level 2.2","parent":"Level 2","content":"Level 2.2\n","description":"Level 2.2\n"},{"id":17,"href":"/MLSys-Seminar/logistics/","title":"Logistics","parent":"Machine Learning System Seminar","content":" Grading The tentative grading breakdown for this course is as follows:\nParticipation: 15% Paper Presentation \u0026amp; Discussion: 15% Paper Summary: 10% Project Proposal: 5% Project Mid-Semester Presentations: 10% Project Final Presentations: 10% Project Final Report: 35% Groups All course activities (except your own participation) will be performed in groups of 4–5 students. Please form your group and submit your group membership and paper preferences by January 31. After this deadline, the instructor will assign remaining students into groups. Academic Integrity The University’s Honor Code applies to all activities in this course. All submitted materials (reading responses, project reports, presentation slides, etc.) must be your own work. If you reference or use external materials, you must cite them properly. AI Tool Policy Permitted: AI tools may be used for grammar checking and refining initial brainstorms. Not Permitted: The final written content, analyses, and code must be authored by the student. Students are fully responsible for the content they submit and must adhere to the Academic Integrity Policy. ","description":" Grading The tentative grading breakdown for this course is as follows:\nParticipation: 15% Paper Presentation \u0026amp; Discussion: 15% Paper Summary: 10% Project Proposal: 5% Project Mid-Semester Presentations: 10% Project Final Presentations: 10% Project Final Report: 35% Groups All course activities (except your own participation) will be performed in groups of 4–5 students. Please form your group and submit your group membership and paper preferences by January 31. After this deadline, the instructor will assign remaining students into groups. Academic Integrity The University’s Honor Code applies to all activities in this course. All submitted materials (reading responses, project reports, presentation slides, etc.) must be your own work. If you reference or use external materials, you must cite them properly. AI Tool Policy Permitted: AI tools may be used for grammar checking and refining initial brainstorms. Not Permitted: The final written content, analyses, and code must be authored by the student. Students are fully responsible for the content they submit and must adhere to the Academic Integrity Policy. "},{"id":18,"href":"/MLSys-Seminar/","title":"Machine Learning System Seminar","parent":"","content":" COMP 620 - Fall 2025 This course is a research seminar focused on efficient machine learning systems. This is a crucial area as modern deep neural networks, especially Large Language Models (LLMs) and generative models, demand extraordinary levels of computation. This computational cost hinders their deployment and scaling, creating significant challenges for both resource-constrained edge devices and large-scale cloud infrastructure. This course delves into the cutting-edge techniques that enable powerful and efficient AI applications.\nWe will cover the full stack of AI systems, from low-level kernel optimizations to high-level algorithm and model designs. The course will survey and dissect recent influential research papers in the field.\nTopics include:\nKernel-Level Optimizations: I/O-aware and exact attention mechanisms (e.g., FlashAttention), sparse attention, and custom kernel generation with AI compilers (e.g., TVM, MLIR).\nEfficient LLMs: State-of-the-art techniques for efficient training (e.g., ZeRO, LoRA), inference (e.g., vLLM, speculative decoding), model compression (quantization, pruning), and long-context optimizations.\nEfficient Model Architectures: Design principles for efficient models, including Mixture-of-Experts (MoE) and State Space Models (Mamba).\nGenerative AI Systems: Optimization techniques for emerging modalities, including efficient video generation, super-resolution, and understanding.\nSecure and Private AI: Methods for ensuring model and data security, including watermarking and encryption in the context of large models.models\nThis course is run as a research seminar. The focus will be on critically reading, presenting, and discussing influential papers in efficient AI systems. Through weekly readings and student-led presentations, participants will gain a deep understanding of the key challenges, foundational techniques, and future directions in the field. Approximately every two weeks, we will also host a guest lecture from a leading researcher or engineer from academia or industry, providing direct insights into the state-of-the-art.\nLecture Videos: [Link to be provided]\nTime: Friday 3:00 PM–4:15 PM CST\nLocation: [TBA]\nOffice Hour: [TBA]\nDiscussion: [TBA]\nHomework Submission: [TBA]\nContact:\n[TBD]\nPrerequisites:\n[TBD]\n","description":" COMP 620 - Fall 2025 This course is a research seminar focused on efficient machine learning systems. This is a crucial area as modern deep neural networks, especially Large Language Models (LLMs) and generative models, demand extraordinary levels of computation. This computational cost hinders their deployment and scaling, creating significant challenges for both resource-constrained edge devices and large-scale cloud infrastructure. This course delves into the cutting-edge techniques that enable powerful and efficient AI applications.\n"},{"id":19,"href":"/MLSys-Seminar/materials/","title":"Materials","parent":"Machine Learning System Seminar","content":" Chapter I: Kernel Related Subtopic 1: I/O Aware \u0026amp; Exact Attention Paper Link FlashAttention 1, 2, 3 PDF, PDF, PDF PagedAttention (vLLM) PDF SGLang PDF FlexAttention PDF FlashInfer PDF SpargeAttention PDF SageAttention 1,2 PDF, PDF Subtopic 2: Sparse Attention Paper Link DejaVu PDF H2O PDF SpAttn PDF MoE PDF Deepseek-MoE PDF Subtopic 3: Kernel Generation \u0026amp; Compiler Paper Link TVM PDF Ansor PDF MLIR PDF Subtopic 4: Execution Optimization/Serving Paper Link Alpa PDF Orca PDF FlexGen PDF ZeRO-Offloading PDF Megatron-LM PDF FlashDecoding++ PDF SarathiServe PDF Chapter II: Efficient LLM Subtopic 1: LLM 101 Paper Link Attention is All You Need PDF BERT PDF GPT-3 PDF Scaling Laws PDF RLHF PDF PPO/DPO PDF , PDF Subtopic 2: Efficient Inference \u0026amp; Long-context Paper Link Streaming LLM \u0026amp; DuoAttention PDF, PDF MInference PDF H2O PDF TOVA/KIVI PDF, PDF Speculative Decoding PDF, PDF Multi-token prediction: Deepseek-v3 PDF Subtopic 3: Model Compression (Quant \u0026amp; Pruning) Paper Link LLM.int8()/GPTQ PDF, PDF AWQ PDF LLM Pruner PDF ShearedLlama PDF Subtopic 4: Efficient Training Paper Link ZeRO PDF Megatron-LM PDF LoRA \u0026amp; QLoRA PDF, PDF Subtopic 5: Efficient Model Designs Paper Link Swtich Transformers/Outrageously Large Neural Networks PDF, PDF MLA Attention PDF Mamba PDF Chapter III: Video Generation Subtopic 1: SOTA/Baseline Model Paper Link CogVideoX PDF HunyuanVideo PDF WAN PDF Seaweed-7B PDF Subtopic 2: Optimization Techniques Paper Link Pruning UniCP Cache PDF, need to add more.. Compression PDF Sparsity PDF Subtopic 3: Long Video Generation Paper Link Tuning-Free Multi-Event Long Video Generation PDF Long Context Tuning for Video Generation PDF One-Minute Video Generation with Test-Time Training PDF SKYREELS-V2: INFINITE-LENGTH FILM GENERATIVE MODEL PDF Subtopic 4: Video Super Resolution Paper Link SeedVR PDF MGLD-VSR PDF DynamicScaler PDF Chapter IV: Secure LLM Subtopic 1: Diffusion Model/Flow Matching Subtopic 2: Watermarking Subtopic 3: Efficient CNN Subtopic 4: Encryption Chapter V: MLLM Video Understanding Subtopic 1: SOTA/Baseline Subtopic 2: Optimization Techniques Subtopic 3: Algorithm Design ","description":" Chapter I: Kernel Related Subtopic 1: I/O Aware \u0026amp; Exact Attention Paper Link FlashAttention 1, 2, 3 PDF, PDF, PDF PagedAttention (vLLM) PDF SGLang PDF FlexAttention PDF FlashInfer PDF SpargeAttention PDF SageAttention 1,2 PDF, PDF Subtopic 2: Sparse Attention Paper Link DejaVu PDF H2O PDF SpAttn PDF MoE PDF Deepseek-MoE PDF Subtopic 3: Kernel Generation \u0026amp; Compiler Paper Link TVM PDF Ansor PDF MLIR PDF Subtopic 4: Execution Optimization/Serving Paper Link Alpa PDF Orca PDF FlexGen PDF ZeRO-Offloading PDF Megatron-LM PDF FlashDecoding++ PDF SarathiServe PDF Chapter II: Efficient LLM Subtopic 1: LLM 101 Paper Link Attention is All You Need PDF BERT PDF GPT-3 PDF Scaling Laws PDF RLHF PDF PPO/DPO PDF , PDF Subtopic 2: Efficient Inference \u0026amp; Long-context Paper Link Streaming LLM \u0026amp; DuoAttention PDF, PDF MInference PDF H2O PDF TOVA/KIVI PDF, PDF Speculative Decoding PDF, PDF Multi-token prediction: Deepseek-v3 PDF Subtopic 3: Model Compression (Quant \u0026amp; Pruning) Paper Link LLM.int8()/GPTQ PDF, PDF AWQ PDF LLM Pruner PDF ShearedLlama PDF Subtopic 4: Efficient Training Paper Link ZeRO PDF Megatron-LM PDF LoRA \u0026amp; QLoRA PDF, PDF Subtopic 5: Efficient Model Designs Paper Link Swtich Transformers/Outrageously Large Neural Networks PDF, PDF MLA Attention PDF Mamba PDF Chapter III: Video Generation Subtopic 1: SOTA/Baseline Model Paper Link CogVideoX PDF HunyuanVideo PDF WAN PDF Seaweed-7B PDF Subtopic 2: Optimization Techniques Paper Link Pruning UniCP Cache PDF, need to add more.. Compression PDF Sparsity PDF Subtopic 3: Long Video Generation Paper Link Tuning-Free Multi-Event Long Video Generation PDF Long Context Tuning for Video Generation PDF One-Minute Video Generation with Test-Time Training PDF SKYREELS-V2: INFINITE-LENGTH FILM GENERATIVE MODEL PDF Subtopic 4: Video Super Resolution Paper Link SeedVR PDF MGLD-VSR PDF DynamicScaler PDF Chapter IV: Secure LLM Subtopic 1: Diffusion Model/Flow Matching Subtopic 2: Watermarking Subtopic 3: Efficient CNN Subtopic 4: Encryption Chapter V: MLLM Video Understanding Subtopic 1: SOTA/Baseline Subtopic 2: Optimization Techniques Subtopic 3: Algorithm Design "},{"id":20,"href":"/MLSys-Seminar/schedule/","title":"Schedule","parent":"Machine Learning System Seminar","content":" Date Lecture Materials Logistics Aug 293:00 PM–4:15 PM Introduction [Slides] Chapter I: Kernel Related Sep 53:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM I/O Aware \u0026amp; Exact Attention [Slides] [Link] Sep 123:00 PM–4:15 PM Sparse Attention [Slides] [Link] Sep 193:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Kernel Generation \u0026amp; Compiler [Slides] [Link] Sep 263:00 PM–4:15 PM Execution Optimization/Serving [Slides] [Link] Chapter II: Efficient LLM Oct 33:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM LLM 101 [Slides] [Link] Oct 103:00 PM–4:15 PM Efficient Inference \u0026amp; Long-context [Slides] [Link] Oct 173:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Model Compression (Quant \u0026amp; Pruning) [Slides] [Link] Oct 243:00 PM–4:15 PM Efficient Training [Slides] [Link] Oct 313:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Efficient Model Designs [Slides] [Link] Chapter III: Video Generation Nov 73:00 PM–4:15 PM SOTA/Baseline Model [Slides] [Link] Nov 143:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Optimization Techniques [Slides] [Link] Nov 213:00 PM–4:15 PM Long Video Generation [Slides] [Link] Nov 283:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Video Super Resolution [Slides] [Link] Chapter IV: Secure LLM Dec 53:00 PM–4:15 PM Diffusion Model/Flow Matching [Slides] [Link] Dec 123:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Watermarking [Slides] [Link] Dec 193:00 PM–4:15 PM Efficient CNN [Slides] [Link] Dec 263:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Encryption [Slides] [Link] Chapter V: MLLM Video Understanding Jan 23:00 PM–4:15 PM SOTA/Baseline [Slides] [Link] Jan 93:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Optimization Techniques [Slides] [Link] Jan 163:00 PM–4:15 PM Algorithm Design [Slides] [Link] Jan 233:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined ","description":" Date Lecture Materials Logistics Aug 293:00 PM–4:15 PM Introduction [Slides] Chapter I: Kernel Related Sep 53:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM I/O Aware \u0026amp; Exact Attention [Slides] [Link] Sep 123:00 PM–4:15 PM Sparse Attention [Slides] [Link] Sep 193:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Kernel Generation \u0026amp; Compiler [Slides] [Link] Sep 263:00 PM–4:15 PM Execution Optimization/Serving [Slides] [Link] Chapter II: Efficient LLM Oct 33:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM LLM 101 [Slides] [Link] Oct 103:00 PM–4:15 PM Efficient Inference \u0026amp; Long-context [Slides] [Link] Oct 173:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Model Compression (Quant \u0026amp; Pruning) [Slides] [Link] Oct 243:00 PM–4:15 PM Efficient Training [Slides] [Link] Oct 313:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Efficient Model Designs [Slides] [Link] Chapter III: Video Generation Nov 73:00 PM–4:15 PM SOTA/Baseline Model [Slides] [Link] Nov 143:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Optimization Techniques [Slides] [Link] Nov 213:00 PM–4:15 PM Long Video Generation [Slides] [Link] Nov 283:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Video Super Resolution [Slides] [Link] Chapter IV: Secure LLM Dec 53:00 PM–4:15 PM Diffusion Model/Flow Matching [Slides] [Link] Dec 123:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Watermarking [Slides] [Link] Dec 193:00 PM–4:15 PM Efficient CNN [Slides] [Link] Dec 263:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Encryption [Slides] [Link] Chapter V: MLLM Video Understanding Jan 23:00 PM–4:15 PM SOTA/Baseline [Slides] [Link] Jan 93:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined 3:40 PM–4:15 PM Optimization Techniques [Slides] [Link] Jan 163:00 PM–4:15 PM Algorithm Design [Slides] [Link] Jan 233:00 PM–3:40 PM Guest Lecture: [Lecturer TBA] [bio] Topic Not ConfirmedTo Be Determined "},{"id":21,"href":"/MLSys-Seminar/staffers/","title":"Staff","parent":"Machine Learning System Seminar","content":" ","description":""},{"id":22,"href":"/MLSys-Seminar/tags/","title":"Tags","parent":"Machine Learning System Seminar","content":"","description":""},{"id":23,"href":"/MLSys-Seminar/toc-tree/","title":"ToC-Tree","parent":"Machine Learning System Seminar","content":"This is just a demo section for the toc-tree shortcode.\nLevel 1 Level 1.1 Level 1.2 Level 1.3 Level 1.3.1 Level 2 Level 2.1 Level 2.2 ","description":"This is just a demo section for the toc-tree shortcode.\nLevel 1 Level 1.1 Level 1.2 Level 1.3 Level 1.3.1 Level 2 Level 2.1 Level 2.2 "}]